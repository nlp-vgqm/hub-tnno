import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from collections import Counter
import time
import re
import warnings

warnings.filterwarnings('ignore')

# æ–‡æœ¬å¤„ç†
import jieba
from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer
import logging

jieba.setLogLevel(logging.ERROR)

# æœºå™¨å­¦ä¹ æ¨¡å‹
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier

# è¯„ä¼°å’Œå·¥å…·
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.preprocessing import LabelEncoder
import os


class DataAnalyzer:
    """æ•°æ®åˆ†æå™¨"""
    def __init__(self, data_path=None, data=None, text_col='review', label_col='label'):
        self.df = pd.read_csv(data_path, encoding='utf-8')
        self.text_col = text_col
        self.label_col = label_col
        self.analyze()

    def analyze(self):
        """è¿›è¡Œæ•°æ®åˆ†æ"""
        print("=" * 50)
        print("æ•°æ®ç»Ÿè®¡åˆ†æ")
        print("=" * 50)

        # åŸºæœ¬ç»Ÿè®¡
        print(f"æ€»æ ·æœ¬æ•°: {len(self.df)}")

        # ç»Ÿè®¡å¥½è¯„å’Œå·®è¯„æ•°é‡
        if 'å¥½è¯„' in self.df[self.label_col].values and 'å·®è¯„' in self.df[self.label_col].values:
            print(f"æ­£æ ·æœ¬æ•°(å¥½è¯„): {len(self.df[self.df[self.label_col] == 'å¥½è¯„'])}")
            print(f"è´Ÿæ ·æœ¬æ•°(å·®è¯„): {len(self.df[self.df[self.label_col] == 'å·®è¯„'])}")
        else:
            # æ˜¾ç¤ºæ‰€æœ‰æ ‡ç­¾çš„åˆ†å¸ƒ
            label_counts = self.df[self.label_col].value_counts()
            print("æ ‡ç­¾åˆ†å¸ƒ:")
            for label, count in label_counts.items():
                print(f"  {label}: {count}")

        # æ–‡æœ¬é•¿åº¦åˆ†æ
        self.df['text_length'] = self.df[self.text_col].apply(len)
        self.df['word_count'] = self.df[self.text_col].apply(lambda x: len(jieba.lcut(x)))

        print(f"\næ–‡æœ¬é•¿åº¦ç»Ÿè®¡:")
        print(f"å¹³å‡å­—ç¬¦æ•°: {self.df['text_length'].mean():.2f}")
        print(f"æœ€å¤§å­—ç¬¦æ•°: {self.df['text_length'].max()}")
        print(f"æœ€å°å­—ç¬¦æ•°: {self.df['text_length'].min()}")

        print(f"\nåˆ†è¯åç»Ÿè®¡:")
        print(f"å¹³å‡è¯æ•°: {self.df['word_count'].mean():.2f}")

        # è¯é¢‘åˆ†æ
        self.analyze_word_freq()

        return self.df

    def analyze_word_freq(self):
        """åˆ†æè¯é¢‘"""
        all_text = ' '.join(self.df[self.text_col].tolist())
        words = jieba.lcut(all_text)

        # è¿‡æ»¤åœç”¨è¯å’ŒçŸ­è¯
        stop_words = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'æˆ‘', 'æœ‰', 'å’Œ', 'å°±',
                          'ä¸', 'äºº', 'éƒ½', 'ä¸€', 'ä¸€ä¸ª', 'ä¸Š', 'ä¹Ÿ', 'å¾ˆ',
                          'åˆ°', 'è¯´', 'è¦', 'å»', 'ä½ ', 'ä¼š', 'ç€', 'æ²¡æœ‰',
                          'çœ‹', 'å¥½', 'è‡ªå·±', 'è¿™'])

        words_filtered = [w for w in words if len(w) > 1 and w not in stop_words]

        # ç»Ÿè®¡è¯é¢‘
        word_freq = Counter(words_filtered)

        print(f"\né«˜é¢‘è¯æ±‡(top 10):")
        for word, freq in word_freq.most_common(10):
            print(f"  {word}: {freq}")

    def visualize(self):
        """å¯è§†åŒ–åˆ†æç»“æœ"""
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))

        # ç±»åˆ«åˆ†å¸ƒ
        ax1 = axes[0, 0]
        label_counts = self.df[self.label_col].value_counts()
        colors = ['green', 'red'] if len(label_counts) == 2 else plt.cm.Set3(np.linspace(0, 1, len(label_counts)))
        ax1.bar(label_counts.index, label_counts.values, color=colors)
        ax1.set_title('ç±»åˆ«åˆ†å¸ƒ')
        ax1.set_ylabel('æ•°é‡')
        ax1.tick_params(axis='x', rotation=45)

        # æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ
        ax2 = axes[0, 1]
        ax2.hist(self.df['text_length'], bins=30, alpha=0.7, color='blue')
        ax2.set_title('æ–‡æœ¬é•¿åº¦åˆ†å¸ƒ')
        ax2.set_xlabel('å­—ç¬¦æ•°')
        ax2.set_ylabel('é¢‘æ•°')

        # è¯æ•°åˆ†å¸ƒ
        ax3 = axes[1, 0]
        ax3.hist(self.df['word_count'], bins=30, alpha=0.7, color='orange')
        ax3.set_title('è¯æ•°åˆ†å¸ƒ')
        ax3.set_xlabel('è¯æ•°')
        ax3.set_ylabel('é¢‘æ•°')

        # ç®±çº¿å›¾
        ax4 = axes[1, 1]
        data_to_plot = []
        labels = []
        for label in self.df[self.label_col].unique():
            data_to_plot.append(self.df[self.df[self.label_col] == label]['text_length'])
            labels.append(label)
        ax4.boxplot(data_to_plot, labels=labels)
        ax4.set_title('æ–‡æœ¬é•¿åº¦ç®±çº¿å›¾')
        ax4.set_ylabel('å­—ç¬¦æ•°')
        ax4.tick_params(axis='x', rotation=45)

        plt.tight_layout()
        plt.show()


class TextPreprocessor:
    """æ–‡æœ¬é¢„å¤„ç†å™¨"""

    def __init__(self):
        self.vectorizer = None

    def clean_text(self, text):
        """æ¸…æ´—æ–‡æœ¬"""
        text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)  # ä¿ç•™ä¸­æ–‡å’Œå­—æ¯æ•°å­—
        text = re.sub(r'\d+', '', text)  # å»é™¤æ•°å­—
        text = re.sub(r'\s+', ' ', text).strip()  # å»é™¤å¤šä½™ç©ºæ ¼
        return text

    def tokenize(self, text):
        """åˆ†è¯"""
        return jieba.lcut(text)

    def preprocess(self, texts, fit=True):
        """é¢„å¤„ç†æ–‡æœ¬"""
        cleaned_texts = [self.clean_text(text) for text in texts]
        # ' 'ï¼ˆä¸€ä¸ªç©ºæ ¼å­—ç¬¦ä¸²ï¼‰æ˜¯è¿æ¥ç¬¦ï¼Œå®ƒçš„ä½œç”¨æ˜¯å°†åˆ†è¯åçš„è¯è¯­åˆ—è¡¨ç”¨ç©ºæ ¼é‡æ–°è¿æ¥æˆä¸€ä¸ªå­—ç¬¦ä¸²
        # ä¸ºä»€ä¹ˆç”¨ç©ºæ ¼ï¼Ÿ
        # å› ä¸ºTF-IDFå‘é‡åŒ–å™¨é»˜è®¤æŒ‰ç©ºæ ¼åˆ†éš”è¯è¯­
        tokenized_texts = [' '.join(self.tokenize(text)) for text in cleaned_texts]
        return tokenized_texts

    def extract_tfidf_features(self, texts, fit=True, max_features=3000):
        """æå–TF-IDFç‰¹å¾"""
        if fit or self.vectorizer is None:
            self.vectorizer = TfidfVectorizer(
                max_features=max_features,
                token_pattern=r'(?u)\b\w+\b',
                ngram_range=(1, 2)  # ä½¿ç”¨unigramå’Œbigram
            )
            features = self.vectorizer.fit_transform(texts)
        else:
            features = self.vectorizer.transform(texts)
        return features


class ModelComparator:
    """æ¨¡å‹æ¯”è¾ƒå™¨"""

    def __init__(self):
        self.results = []

    def train_and_evaluate(self, model_info, X_train, X_val, y_train, y_val):
        """è®­ç»ƒå’Œè¯„ä¼°å•ä¸ªæ¨¡å‹"""
        model_name = model_info['name']
        model = model_info['model']
        learning_rate = model_info.get('learning_rate', None)
        hidden_size = model_info.get('hidden_size', None)

        print(f"\nè®­ç»ƒ {model_name}...")
        if learning_rate is not None:
            print(f"  å­¦ä¹ ç‡: {learning_rate}")
        if hidden_size is not None:
            print(f"  éšè—å±‚å¤§å°: {hidden_size}")

        # è®­ç»ƒæ—¶é—´
        start_train = time.time()
        model.fit(X_train, y_train)
        train_time = time.time() - start_train

        # é¢„æµ‹æ—¶é—´
        start_predict = time.time()
        y_pred = model.predict(X_val)
        predict_time = time.time() - start_predict

        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_val, y_pred)
        precision = precision_score(y_val, y_pred, average='weighted', zero_division=0)
        recall = recall_score(y_val, y_pred, average='weighted', zero_division=0)
        # F1åˆ†æ•°æ˜¯æœºå™¨å­¦ä¹ å’Œç»Ÿè®¡åˆ†ç±»é—®é¢˜ä¸­å¸¸ç”¨çš„ä¸€ä¸ªè¡¡é‡æ¨¡å‹æ€§èƒ½çš„æŒ‡æ ‡ï¼Œå®ƒåŒæ—¶è€ƒè™‘äº†ç²¾ç¡®ç‡ï¼ˆPrecisionï¼‰å’Œå¬å›ç‡ï¼ˆRecallï¼‰ï¼Œæ˜¯äºŒè€…çš„è°ƒå’Œå¹³å‡æ•°ã€‚
        f1 = f1_score(y_val, y_pred, average='weighted', zero_division=0)

        # è·å–æ ·æœ¬æ•°é‡ï¼ˆä½¿ç”¨shape[0]è€Œä¸æ˜¯len()ï¼‰
        n_samples = X_val.shape[0]

        # ä¿å­˜ç»“æœ
        result = {
            'æ¨¡å‹': model_name,
            'å‡†ç¡®ç‡(acc)': accuracy,
            'ç²¾ç¡®ç‡': precision,
            'å¬å›ç‡': recall,
            'F1åˆ†æ•°': f1,
            'è®­ç»ƒæ—¶é—´(s)': train_time,
            'é¢„æµ‹æ—¶é—´(s)': predict_time,
            'é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)': (predict_time / n_samples) * 1000 if n_samples > 0 else 0,
            'å­¦ä¹ ç‡': learning_rate if learning_rate is not None else '-',
            'éšè—å±‚å¤§å°': hidden_size if hidden_size is not None else '-'
        }

        self.results.append(result)

        print(f"  å‡†ç¡®ç‡(acc): {accuracy:.4f}")
        print(f"  F1åˆ†æ•°: {f1:.4f}")
        print(f"  è®­ç»ƒæ—¶é—´: {train_time:.3f}s")
        print(f"  é¢„æµ‹æ—¶é—´: {predict_time:.3f}s")

        return result


class ExperimentRunner:
    """å®éªŒè¿è¡Œå™¨"""

    def __init__(self, data_path=None, data=None):
        self.data_path = data_path
        self.data = data
        self.comparator = ModelComparator()
        self.models = []
        self.feature_names = []

    def setup_models(self):
        """è®¾ç½®è¦æ¯”è¾ƒçš„æ¨¡å‹"""
        # åŸºç¡€æ¨¡å‹é…ç½®ï¼ˆä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹ï¼‰
        self.models = [
            {
                'name': 'é€»è¾‘å›å½’',
                'model': LogisticRegression(max_iter=2000, random_state=42, C=0.8),
                'learning_rate': None,
                'hidden_size': None
            },
            {
                'name': 'æœ´ç´ è´å¶æ–¯',
                'model': MultinomialNB(alpha=1.0),
                'learning_rate': None,
                'hidden_size': None
            },
            {
                'name': 'æ”¯æŒå‘é‡æœº',
                'model': SVC(kernel='linear', probability=True, random_state=42, C=1.0),
                'learning_rate': None,
                'hidden_size': None
            },
            {
                'name': 'éšæœºæ£®æ—',
                'model': RandomForestClassifier(n_estimators=100, random_state=42, max_depth=None),
                'learning_rate': None,
                'hidden_size': None
            },
            # MLPç¥ç»ç½‘ç»œæ¨¡å‹ - ä¸åŒå­¦ä¹ ç‡
            {
                'name': 'MLP(å­¦ä¹ ç‡0.001)',
                'model': MLPClassifier(
                    hidden_layer_sizes=(100,),
                    learning_rate_init=0.001,
                    max_iter=500,    # æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå³æœ€å¤§ epoch æ•°
                    random_state=42,
                    early_stopping=True
                ),
                'learning_rate': 0.001,
                'hidden_size': 100
            },
            {
                'name': 'MLP(å­¦ä¹ ç‡0.01)',
                'model': MLPClassifier(
                    hidden_layer_sizes=(100,),
                    learning_rate_init=0.01,
                    max_iter=500,
                    random_state=42,
                    early_stopping=True
                ),
                'learning_rate': 0.01,
                'hidden_size': 100
            },
            # MLPç¥ç»ç½‘ç»œæ¨¡å‹ - ä¸åŒéšè—å±‚å¤§å°
            {
                'name': 'MLP(éšè—å±‚50)',
                'model': MLPClassifier(
                    hidden_layer_sizes=(50,),
                    learning_rate_init=0.01,
                    max_iter=500,
                    random_state=42,
                    early_stopping=True
                ),
                'learning_rate': 0.01,
                'hidden_size': 50
            },
            {
                'name': 'MLP(éšè—å±‚100,50)',
                'model': MLPClassifier(
                    hidden_layer_sizes=(100, 50),
                    learning_rate_init=0.01,
                    max_iter=500,
                    random_state=42,
                    early_stopping=True
                ),
                'learning_rate': 0.01,
                'hidden_size': '100,50'
            },
            {
                'name': 'MLP(éšè—å±‚200,100)',
                'model': MLPClassifier(
                    hidden_layer_sizes=(200, 100),
                    learning_rate_init=0.01,
                    max_iter=500,
                    random_state=42,
                    early_stopping=True
                ),
                'learning_rate': 0.01,
                'hidden_size': '200,100'
            },
            {
                'name': 'MLP(éšè—å±‚400,200,200,å­¦ä¹ ç‡0.01)',
                'model': MLPClassifier(
                    hidden_layer_sizes=(400, 200, 200),
                    learning_rate_init=0.01,
                    max_iter=500,
                    random_state=42,
                    early_stopping=True
                ),
                'learning_rate': 0.01,
                'hidden_size': '400,200,200'
            }
        ]

        # å°è¯•æ·»åŠ é¢å¤–çš„æ¨¡å‹
        try:
            from sklearn.linear_model import SGDClassifier
            self.models.append({
                'name': 'SGDåˆ†ç±»å™¨',   # éšæœºæ¢¯åº¦ä¸‹é™
                'model': SGDClassifier(
                    loss='hinge',
                    penalty='l2',
                    max_iter=1000,
                    random_state=42,
                    learning_rate='optimal'
                ),
                'learning_rate': 'optimal',
                'hidden_size': None
            })
        except:
            pass

        try:
            from sklearn.neighbors import KNeighborsClassifier
            self.models.append({
                'name': 'KNN',    # kè¿‘é‚»ç®—æ³•
                'model': KNeighborsClassifier(n_neighbors=5),
                'learning_rate': None,
                'hidden_size': None
            })
        except:
            pass

    def run_experiment(self):
        """è¿è¡Œå®Œæ•´å®éªŒ"""
        print("=" * 60)
        print("ç½‘ç»œè´­ç‰©è¯„è®ºåˆ†ç±»å®éªŒ")
        print("=" * 60)

        # 1. æ•°æ®åŠ è½½å’Œåˆ†æ
        print("\n1. æ•°æ®åŠ è½½å’Œåˆ†æ")
        analyzer = DataAnalyzer(data_path=self.data_path, data=self.data)
        df = analyzer.df

        # 2. æ•°æ®é¢„å¤„ç†
        print("\n2. æ•°æ®é¢„å¤„ç†")
        preprocessor = TextPreprocessor()
        texts = df['review'].tolist()
        labels = df['label'].tolist()

        # ç¼–ç æ ‡ç­¾ï¼Œæ­¤æ­¥éª¤å¯ä»¥çœç•¥
        le = LabelEncoder()
        y = le.fit_transform(labels)

        # æ˜¾ç¤ºæ ‡ç­¾æ˜ å°„
        print(f"æ ‡ç­¾ç¼–ç : {dict(zip(le.classes_, le.transform(le.classes_)))}")

        # é¢„å¤„ç†æ–‡æœ¬
        processed_texts = preprocessor.preprocess(texts)

        # æå–ç‰¹å¾
        X = preprocessor.extract_tfidf_features(processed_texts, fit=True)
        self.feature_names = preprocessor.vectorizer.get_feature_names_out()

        print(f"ç‰¹å¾ç»´åº¦: {X.shape}")
        print(f"ç‰¹å¾æ•°é‡: {len(self.feature_names)}")

        # 3. åˆ’åˆ†è®­ç»ƒé›†å’ŒéªŒè¯é›†
        # train_test_split(
        # Xâ€Œï¼šç‰¹å¾æ•°æ®ï¼ˆè¾“å…¥å˜é‡ï¼‰ï¼Œé€šå¸¸ä¸ºäºŒç»´æ•°ç»„æˆ– DataFrameã€‚
        # yâ€Œï¼šç›®æ ‡å˜é‡ï¼ˆè¾“å‡ºå˜é‡ï¼‰ï¼Œé€šå¸¸ä¸ºä¸€ç»´æ•°ç»„æˆ– Seriesã€‚
        # test_sizeâ€Œï¼šæµ‹è¯•é›†å æ¯”ï¼ˆæµ®ç‚¹æ•°ï¼Œå¦‚ 0.25 è¡¨ç¤º 25%ï¼‰æˆ–æ ·æœ¬æ•°é‡ï¼ˆæ•´æ•°ï¼‰ã€‚â€Œ
        # random_stateâ€Œï¼šéšæœºç§å­ï¼Œç¡®ä¿æ¯æ¬¡æ‹†åˆ†ç»“æœå¯é‡å¤ï¼ˆä¾‹å¦‚ï¼Œè®¾ç½®ä¸º 0 æˆ– 1 æ—¶ç»“æœä¸€è‡´ï¼‰
        # shuffleâ€Œï¼šå¸ƒå°”å€¼ï¼Œæ˜¯å¦åœ¨æ‹†åˆ†å‰æ‰“ä¹±æ•°æ®ï¼ˆé»˜è®¤ä¸º Trueï¼‰ã€‚â€Œ
        # tratifyâ€Œï¼šå¦‚æœæŒ‡å®šï¼Œä¼šæŒ‰ç›®æ ‡å˜é‡çš„åˆ†å¸ƒè¿›è¡Œåˆ†å±‚æŠ½æ ·ï¼Œç¡®ä¿è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¸­çš„ç±»åˆ«æ¯”ä¾‹ä¸€è‡´ï¼ˆé€‚ç”¨äºåˆ†ç±»é—®é¢˜ï¼‰)
        X_train, X_val, y_train, y_val = train_test_split(
            X, y, test_size=0.2, random_state=42, stratify=y
        )

        print(f"\nè®­ç»ƒé›†å¤§å°: {X_train.shape[0]}")  # ä½¿ç”¨shape[0]è·å–æ ·æœ¬æ•°
        print(f"éªŒè¯é›†å¤§å°: {X_val.shape[0]}")  # ä½¿ç”¨shape[0]è·å–æ ·æœ¬æ•°

        # 4. è®¾ç½®æ¨¡å‹
        self.setup_models()

        # 5. è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹
        print("\n3. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°")
        print("-" * 60)

        for model_info in self.models:
            try:
                self.comparator.train_and_evaluate(
                    model_info, X_train, X_val, y_train, y_val
                )
            except Exception as e:
                print(f"è®­ç»ƒ {model_info['name']} æ—¶å‡ºé”™: {e}")

        # 6. æ˜¾ç¤ºç»“æœ
        print("\n4. å®éªŒç»“æœæ€»ç»“")
        print("=" * 60)

        results_df = pd.DataFrame(self.comparator.results)
        results_df = results_df.sort_values('å‡†ç¡®ç‡(acc)', ascending=False)

        self.display_results_table(results_df)
        self.visualize_results(results_df)
        self.analyze_model_parameters(results_df)
        self.analyze_important_features(results_df, preprocessor.vectorizer)

        return results_df

    def display_results_table(self, results_df):
        """æ˜¾ç¤ºç»“æœè¡¨æ ¼"""
        print("\næ¨¡å‹æ€§èƒ½å¯¹æ¯”è¡¨:")
        print("-" * 100)
        print(
            f"{'æ¨¡å‹':<20} {'å‡†ç¡®ç‡(acc)':<12} {'F1åˆ†æ•°':<10} {'å­¦ä¹ ç‡':<10} {'éšè—å±‚å¤§å°':<12} {'è®­ç»ƒæ—¶é—´(s)':<12} {'é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)':<20}")
        print("-" * 100)

        for _, row in results_df.iterrows():
            print(f"{row['æ¨¡å‹']:<20} {row['å‡†ç¡®ç‡(acc)']:<12.4f} {row['F1åˆ†æ•°']:<10.4f} "
                  f"{str(row['å­¦ä¹ ç‡']):<10} {str(row['éšè—å±‚å¤§å°']):<12} "
                  f"{row['è®­ç»ƒæ—¶é—´(s)']:<12.3f} {row['é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)']:<20.4f}")

        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        results_df.to_csv('model_comparison_results.csv', index=False, encoding='utf-8')
        print(f"\nè¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: model_comparison_results.csv")

    def visualize_results(self, results_df):
        """å¯è§†åŒ–ç»“æœ"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))

        # 1. å‡†ç¡®ç‡å¯¹æ¯”
        ax1 = axes[0, 0]
        models = results_df['æ¨¡å‹']
        accuracy = results_df['å‡†ç¡®ç‡(acc)']
        bars1 = ax1.barh(models, accuracy, color='skyblue')
        ax1.set_xlabel('å‡†ç¡®ç‡(acc)')
        ax1.set_title('æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”')
        ax1.set_xlim([0, 1])
        # åœ¨æ¡å½¢ä¸Šæ·»åŠ æ•°å€¼
        for bar in bars1:
            width = bar.get_width()
            ax1.text(width, bar.get_y() + bar.get_height() / 2,
                     f'{width:.3f}', ha='left', va='center', fontsize=8)

        # 2. F1åˆ†æ•°å¯¹æ¯”
        ax2 = axes[0, 1]
        f1_scores = results_df['F1åˆ†æ•°']
        bars2 = ax2.barh(models, f1_scores, color='lightgreen')
        ax2.set_xlabel('F1åˆ†æ•°')
        ax2.set_title('æ¨¡å‹F1åˆ†æ•°å¯¹æ¯”')
        ax2.set_xlim([0, 1])
        for bar in bars2:
            width = bar.get_width()
            ax2.text(width, bar.get_y() + bar.get_height() / 2,
                     f'{width:.3f}', ha='left', va='center', fontsize=8)

        # 3. è®­ç»ƒæ—¶é—´å¯¹æ¯”
        ax3 = axes[0, 2]
        train_times = results_df['è®­ç»ƒæ—¶é—´(s)']
        bars3 = ax3.barh(models, train_times, color='salmon')
        ax3.set_xlabel('è®­ç»ƒæ—¶é—´(s)')
        ax3.set_title('æ¨¡å‹è®­ç»ƒæ—¶é—´å¯¹æ¯”')
        for bar in bars3:
            width = bar.get_width()
            ax3.text(width, bar.get_y() + bar.get_height() / 2,
                     f'{width:.3f}s', ha='left', va='center', fontsize=8)

        # 4. é¢„æµ‹é€Ÿåº¦å¯¹æ¯”
        ax4 = axes[1, 0]
        pred_times = results_df['é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)']
        bars4 = ax4.barh(models, pred_times, color='gold')
        ax4.set_xlabel('é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)')
        ax4.set_title('æ¨¡å‹é¢„æµ‹é€Ÿåº¦å¯¹æ¯”')
        for bar in bars4:
            width = bar.get_width()
            ax4.text(width, bar.get_y() + bar.get_height() / 2,
                     f'{width:.2f}ms', ha='left', va='center', fontsize=8)

        # 5. å­¦ä¹ ç‡ä¸å‡†ç¡®ç‡å…³ç³»ï¼ˆä»…å¯¹æœ‰å­¦ä¹ ç‡çš„æ¨¡å‹ï¼‰
        ax5 = axes[1, 1]
        mlp_results = results_df[results_df['å­¦ä¹ ç‡'] != '-']
        if len(mlp_results) > 0:
            # æå–æ•°å€¼å‹å­¦ä¹ ç‡
            learning_rates = []
            accuracies = []
            for _, row in mlp_results.iterrows():
                try:
                    lr = float(row['å­¦ä¹ ç‡'])
                    learning_rates.append(lr)
                    accuracies.append(row['å‡†ç¡®ç‡(acc)'])
                except:
                    pass

            if len(learning_rates) > 0:
                ax5.scatter(learning_rates, accuracies, color='purple', s=100)
                ax5.set_xlabel('å­¦ä¹ ç‡')
                ax5.set_ylabel('å‡†ç¡®ç‡(acc)')
                ax5.set_title('å­¦ä¹ ç‡ vs å‡†ç¡®ç‡')
                ax5.set_xscale('log')
                # æ·»åŠ æ¨¡å‹æ ‡ç­¾
                for i, (_, row) in enumerate(mlp_results.iterrows()):
                    try:
                        lr = float(row['å­¦ä¹ ç‡'])
                        ax5.annotate(row['æ¨¡å‹'], (lr, row['å‡†ç¡®ç‡(acc)']),
                                     xytext=(5, 5), textcoords='offset points', fontsize=8)
                    except:
                        pass

        # 6. éšè—å±‚å¤§å°ä¸æ€§èƒ½å…³ç³»
        ax6 = axes[1, 2]
        # åªæ˜¾ç¤ºæœ‰éšè—å±‚å¤§å°çš„æ¨¡å‹
        hidden_size_results = results_df[results_df['éšè—å±‚å¤§å°'] != '-']
        if len(hidden_size_results) > 0:
            hidden_sizes = []
            accuracies = []
            for _, row in hidden_size_results.iterrows():
                hidden_sizes.append(str(row['éšè—å±‚å¤§å°']))
                accuracies.append(row['å‡†ç¡®ç‡(acc)'])

            # åˆ›å»ºæ¡å½¢å›¾
            x_pos = np.arange(len(hidden_sizes))
            bars6 = ax6.bar(x_pos, accuracies, color='lightcoral')
            ax6.set_xlabel('éšè—å±‚å¤§å°')
            ax6.set_ylabel('å‡†ç¡®ç‡(acc)')
            ax6.set_title('éšè—å±‚å¤§å° vs å‡†ç¡®ç‡')
            ax6.set_xticks(x_pos)
            ax6.set_xticklabels(hidden_sizes, rotation=45, ha='right')
            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bar, acc in zip(bars6, accuracies):
                height = bar.get_height()
                ax6.text(bar.get_x() + bar.get_width() / 2., height,
                         f'{acc:.3f}', ha='center', va='bottom', fontsize=8)

        plt.tight_layout()
        plt.savefig('model_comparison.png', dpi=150, bbox_inches='tight')
        plt.show()

        # ç»¼åˆæ€§èƒ½æ•£ç‚¹å›¾
        fig, ax = plt.subplots(figsize=(12, 8))

        # åˆ›å»ºæ•£ç‚¹å›¾ï¼Œæ°”æ³¡å¤§å°è¡¨ç¤ºF1åˆ†æ•°
        scatter = ax.scatter(
            results_df['è®­ç»ƒæ—¶é—´(s)'],
            results_df['å‡†ç¡®ç‡(acc)'],
            s=results_df['F1åˆ†æ•°'] * 500,  # æ°”æ³¡å¤§å°
            c=results_df['é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)'],
            alpha=0.6,
            cmap='viridis'
        )

        ax.set_xlabel('è®­ç»ƒæ—¶é—´(s)')
        ax.set_ylabel('å‡†ç¡®ç‡(acc)')
        ax.set_title('æ¨¡å‹ç»¼åˆæ€§èƒ½å¯¹æ¯”ï¼ˆæ°”æ³¡å¤§å°=F1åˆ†æ•°ï¼Œé¢œè‰²=é¢„æµ‹æ—¶é—´ï¼‰')

        # æ·»åŠ æ¨¡å‹æ ‡ç­¾
        for i, row in results_df.iterrows():
            ax.annotate(
                row['æ¨¡å‹'],
                (row['è®­ç»ƒæ—¶é—´(s)'], row['å‡†ç¡®ç‡(acc)']),
                xytext=(5, 5),
                textcoords='offset points',
                fontsize=8
            )

        plt.colorbar(scatter, label='é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig('model_performance_scatter.png', dpi=150, bbox_inches='tight')
        plt.show()

    def analyze_model_parameters(self, results_df):
        """åˆ†ææ¨¡å‹å‚æ•°å¯¹æ€§èƒ½çš„å½±å“"""
        print("\n5. æ¨¡å‹å‚æ•°åˆ†æ")
        print("-" * 60)

        # åˆ†æå­¦ä¹ ç‡å¯¹æ€§èƒ½çš„å½±å“
        mlp_results = results_df[results_df['å­¦ä¹ ç‡'] != '-']
        if len(mlp_results) > 0:
            print("\nå­¦ä¹ ç‡å¯¹MLPæ¨¡å‹æ€§èƒ½çš„å½±å“:")
            for _, row in mlp_results.iterrows():
                print(f"  æ¨¡å‹: {row['æ¨¡å‹']}, å­¦ä¹ ç‡: {row['å­¦ä¹ ç‡']}, "
                      f"å‡†ç¡®ç‡: {row['å‡†ç¡®ç‡(acc)']:.4f}, è®­ç»ƒæ—¶é—´: {row['è®­ç»ƒæ—¶é—´(s)']:.3f}s")

        # åˆ†æéšè—å±‚å¤§å°å¯¹æ€§èƒ½çš„å½±å“
        hidden_results = results_df[results_df['éšè—å±‚å¤§å°'] != '-']
        if len(hidden_results) > 0:
            print("\néšè—å±‚å¤§å°å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“:")
            for _, row in hidden_results.iterrows():
                print(f"  æ¨¡å‹: {row['æ¨¡å‹']}, éšè—å±‚: {row['éšè—å±‚å¤§å°']}, "
                      f"å‡†ç¡®ç‡: {row['å‡†ç¡®ç‡(acc)']:.4f}, è®­ç»ƒæ—¶é—´: {row['è®­ç»ƒæ—¶é—´(s)']:.3f}s")

        # åˆ†æä¼ ç»Ÿæ¨¡å‹ vs ç¥ç»ç½‘ç»œæ¨¡å‹
        traditional_models = results_df[results_df['éšè—å±‚å¤§å°'] == '-']
        nn_models = results_df[results_df['éšè—å±‚å¤§å°'] != '-']

        if len(traditional_models) > 0 and len(nn_models) > 0:
            print("\nä¼ ç»Ÿæ¨¡å‹ vs ç¥ç»ç½‘ç»œæ¨¡å‹å¯¹æ¯”:")
            trad_avg_acc = traditional_models['å‡†ç¡®ç‡(acc)'].mean()
            nn_avg_acc = nn_models['å‡†ç¡®ç‡(acc)'].mean()
            trad_avg_time = traditional_models['è®­ç»ƒæ—¶é—´(s)'].mean()
            nn_avg_time = nn_models['è®­ç»ƒæ—¶é—´(s)'].mean()

            print(f"  ä¼ ç»Ÿæ¨¡å‹å¹³å‡å‡†ç¡®ç‡: {trad_avg_acc:.4f}")
            print(f"  ç¥ç»ç½‘ç»œå¹³å‡å‡†ç¡®ç‡: {nn_avg_acc:.4f}")
            print(f"  ä¼ ç»Ÿæ¨¡å‹å¹³å‡è®­ç»ƒæ—¶é—´: {trad_avg_time:.3f}s")
            print(f"  ç¥ç»ç½‘ç»œå¹³å‡è®­ç»ƒæ—¶é—´: {nn_avg_time:.3f}s")

            if nn_avg_acc > trad_avg_acc:
                accuracy_gain = (nn_avg_acc - trad_avg_acc) * 100
                print(f"  ç¥ç»ç½‘ç»œå‡†ç¡®ç‡æå‡: +{accuracy_gain:.2f}%")
            else:
                accuracy_loss = (trad_avg_acc - nn_avg_acc) * 100
                print(f"  ç¥ç»ç½‘ç»œå‡†ç¡®ç‡é™ä½: -{accuracy_loss:.2f}%")

    def analyze_important_features(self, results_df, vectorizer):
        """åˆ†æé‡è¦ç‰¹å¾"""
        print("\n6. é‡è¦ç‰¹å¾åˆ†æ")
        print("-" * 60)

        # æ‰¾å‡ºé€»è¾‘å›å½’æ¨¡å‹
        lr_model = None
        for model_info in self.models:
            if model_info['name'] == 'é€»è¾‘å›å½’':
                lr_model = model_info['model']
                break

        if lr_model is not None and hasattr(lr_model, 'coef_'):
            # è·å–ç‰¹å¾é‡è¦æ€§
            feature_importance = lr_model.coef_[0]

            # è·å–æœ€é‡è¦çš„ç‰¹å¾ï¼ˆæ­£é¢å’Œè´Ÿé¢ï¼‰
            top_n = 10
            top_positive_idx = np.argsort(feature_importance)[-top_n:][::-1]
            top_negative_idx = np.argsort(feature_importance)[:top_n]

            print(f"\næœ€é‡è¦çš„æ­£é¢ç‰¹å¾ï¼ˆè¡¨ç¤ºå¥½è¯„ï¼‰:")
            for idx in top_positive_idx:
                if idx < len(self.feature_names):
                    print(f"  {self.feature_names[idx]}: {feature_importance[idx]:.4f}")

            print(f"\næœ€é‡è¦çš„è´Ÿé¢ç‰¹å¾ï¼ˆè¡¨ç¤ºå·®è¯„ï¼‰:")
            for idx in top_negative_idx:
                if idx < len(self.feature_names):
                    print(f"  {self.feature_names[idx]}: {feature_importance[idx]:.4f}")

    def generate_summary_report(self, results_df):
        """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
        print("\n" + "=" * 60)
        print("å®éªŒæ€»ç»“å’Œå»ºè®®")
        print("=" * 60)

        # æ‰¾å‡ºæœ€ä½³æ¨¡å‹
        best_acc_idx = results_df['å‡†ç¡®ç‡(acc)'].idxmax()
        best_acc = results_df.loc[best_acc_idx]

        best_f1_idx = results_df['F1åˆ†æ•°'].idxmax()
        best_f1 = results_df.loc[best_f1_idx]

        fastest_pred_idx = results_df['é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)'].idxmin()
        fastest_pred = results_df.loc[fastest_pred_idx]

        fastest_train_idx = results_df['è®­ç»ƒæ—¶é—´(s)'].idxmin()
        fastest_train = results_df.loc[fastest_train_idx]

        print(f"\nğŸ“Š æ€§èƒ½æ€»ç»“:")
        print(
            f"   æœ€é«˜å‡†ç¡®ç‡æ¨¡å‹: {best_acc['æ¨¡å‹']} (å‡†ç¡®ç‡: {best_acc['å‡†ç¡®ç‡(acc)']:.4f}, å­¦ä¹ ç‡: {best_acc['å­¦ä¹ ç‡']}, éšè—å±‚: {best_acc['éšè—å±‚å¤§å°']})")
        print(f"   æœ€é«˜F1åˆ†æ•°æ¨¡å‹: {best_f1['æ¨¡å‹']} (F1åˆ†æ•°: {best_f1['F1åˆ†æ•°']:.4f})")
        print(f"   æœ€å¿«é¢„æµ‹æ¨¡å‹: {fastest_pred['æ¨¡å‹']} ({fastest_pred['é¢„æµ‹æ—¶é—´/æ ·æœ¬(ms)']:.2f}ms/æ ·æœ¬)")
        print(f"   æœ€å¿«è®­ç»ƒæ¨¡å‹: {fastest_train['æ¨¡å‹']} ({fastest_train['è®­ç»ƒæ—¶é—´(s)']:.3f}s)")

        print(f"\nğŸ¯ å‚æ•°é€‰æ‹©å»ºè®®:")
        if best_acc['å­¦ä¹ ç‡'] != '-':
            print(f"   æœ€ä½³å­¦ä¹ ç‡: {best_acc['å­¦ä¹ ç‡']}")
        if best_acc['éšè—å±‚å¤§å°'] != '-':
            print(f"   æœ€ä½³éšè—å±‚é…ç½®: {best_acc['éšè—å±‚å¤§å°']}")

        # åˆ†æå­¦ä¹ ç‡å»ºè®®
        mlp_models = results_df[results_df['å­¦ä¹ ç‡'] != '-']
        if len(mlp_models) > 0:
            best_lr_model = mlp_models.loc[mlp_models['å‡†ç¡®ç‡(acc)'].idxmax()]
            print(f"   ç¥ç»ç½‘ç»œæœ€ä½³å­¦ä¹ ç‡: {best_lr_model['å­¦ä¹ ç‡']} (å‡†ç¡®ç‡: {best_lr_model['å‡†ç¡®ç‡(acc)']:.4f})")

        print(f"\nğŸ’¡ æ¨¡å‹é€‰æ‹©å»ºè®®:")
        print("   1. å¦‚æœè¿½æ±‚æœ€é«˜å‡†ç¡®ç‡: é€‰æ‹©", best_acc['æ¨¡å‹'])
        print("   2. å¦‚æœè¿½æ±‚å¹³è¡¡æ€§èƒ½: é€‰æ‹©", best_f1['æ¨¡å‹'])
        print("   3. å¦‚æœå¯¹å®æ—¶æ€§è¦æ±‚é«˜: é€‰æ‹©", fastest_pred['æ¨¡å‹'])
        print("   4. å¦‚æœéœ€è¦å¿«é€Ÿè¿­ä»£: é€‰æ‹©", fastest_train['æ¨¡å‹'])
        print("   5. å¦‚æœèµ„æºæœ‰é™: é€‰æ‹©æœ´ç´ è´å¶æ–¯æˆ–é€»è¾‘å›å½’")
        print("   6. å¦‚æœæ•°æ®é‡å¤§ä¸”ç‰¹å¾å¤æ‚: è€ƒè™‘ç¥ç»ç½‘ç»œæ¨¡å‹")

        # ç”Ÿæˆæœ€ç»ˆæ¨è
        if best_acc['æ¨¡å‹'] == best_f1['æ¨¡å‹']:
            print(f"\nğŸ† ç»¼åˆæ¨èæ¨¡å‹: {best_acc['æ¨¡å‹']} (å‡†ç¡®ç‡å’ŒF1åˆ†æ•°éƒ½æœ€ä½³)")
        else:
            print(f"\nğŸ† ç»¼åˆæ¨è:")
            print(f"   é¦–é€‰: {best_acc['æ¨¡å‹']} (å‡†ç¡®ç‡æœ€é«˜)")
            print(f"   å¤‡é€‰: {best_f1['æ¨¡å‹']} (F1åˆ†æ•°æœ€é«˜)")
            print(f"   å¿«é€Ÿé€‰æ‹©: {fastest_pred['æ¨¡å‹']} (é¢„æµ‹æœ€å¿«)")


def main():
    """ä¸»å‡½æ•°"""
    # è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'SimHei', 'Microsoft YaHei', 'sans-serif']
    plt.rcParams['axes.unicode_minus'] = False

    # åˆ›å»ºå®éªŒè¿è¡Œå™¨
    runner = ExperimentRunner(data_path='æ–‡æœ¬åˆ†ç±»ç»ƒä¹ .csv')

    # è¿è¡Œå®éªŒ
    results_df = runner.run_experiment()

    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    runner.generate_summary_report(results_df)

    print("\n" + "=" * 60)
    print("å®éªŒå®Œæˆï¼")
    print("ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - model_comparison_results.csv: æ¨¡å‹æ€§èƒ½è¯¦ç»†ç»“æœ")
    print("  - model_comparison.png: æ¨¡å‹å¯¹æ¯”å›¾")
    print("  - model_performance_scatter.png: ç»¼åˆæ€§èƒ½æ•£ç‚¹å›¾")
    print("=" * 60)


if __name__ == "__main__":
    # # æ£€æŸ¥å¿…è¦çš„åº“
    # required_libraries = ['pandas', 'numpy', 'sklearn', 'jieba', 'matplotlib']
    # print("æ£€æŸ¥å¿…è¦çš„åº“...")
    # for lib in required_libraries:
    #     try:
    #         __import__(lib)
    #         print(f"  âœ“ {lib}")
    #     except ImportError:
    #         print(f"  âœ— {lib} æœªå®‰è£…")
    #         if lib == 'sklearn':
    #             print("    è¯·è¿è¡Œ: pip install scikit-learn")
    #         elif lib == 'jieba':
    #             print("    è¯·è¿è¡Œ: pip install jieba")
    #         else:
    #             print(f"    è¯·è¿è¡Œ: pip install {lib}")

    print("\nå¼€å§‹å®éªŒ...")
    main()
